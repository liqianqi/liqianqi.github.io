---
title: ptè½¬onnxä»£ç 
author: liqianqi
date: 2025-04-28 13:42:00 +0800
categories: [RM]
tags: []
math: false
mermaid: false
pin: false
# image:
#   src: https://raw.githubusercontent.com/Harry-hhj/Harry-hhj.github.io/master/_posts/2021-08-24-Building-your-Blog.assets/devices-mockup.png
#   width: 850
#   height: 585
---

# è½¬æ¢
- ç›®å‰æ‰‹å¤´ä¸Šæœ‰ä¸€äº›æ¨¡å‹ï¼Œæˆ‘ç»å¸¸ä¸çŸ¥é“ä»–ä»¬çš„è¾“å…¥å°ºå¯¸ï¼Œä½†æ˜¯æˆ‘çŸ¥é“ä»–ä»¬å…·ä½“çš„è¾“å‡ºæ ¼å¼, [batch_size, dynamic_input], batch_size é€šå¸¸æ˜¯ 1, æ‰€ä»¥ä»£ç å¦‚ä¸‹: 

```py
import torch
import os

# ==== é…ç½®éƒ¨åˆ† ====
pt_path = 'C:/Users/20416/Desktop/unitree_rl_gym/motion.pt'  # ä½ çš„ptè·¯å¾„
onnx_path = 'C:/Users/20416/Desktop/unitree_rl_gym/motion.onnx'  # è¾“å‡ºonnxè·¯å¾„
min_dim = 1
max_dim = 512
opset = 11  # å¯ä»¥æ”¹æˆ13æˆ–æ›´é«˜ï¼ˆæŒ‰éœ€ï¼‰

# ==== åŠ è½½ TorchScript æ¨¡å‹ ====
print(f"ğŸ”µ æ­£åœ¨åŠ è½½TorchScriptæ¨¡å‹ï¼š{pt_path}")
model = torch.jit.load(pt_path)
model.eval()

# ==== è‡ªåŠ¨æ¢æµ‹è¾“å…¥å°ºå¯¸ ====
print(f"ğŸ› ï¸ å¼€å§‹æ¢æµ‹è¾“å…¥å°ºå¯¸...")
input_dim = None

for dim in range(min_dim, max_dim + 1):
    try:
        dummy_input = torch.randn(1, dim)
        with torch.no_grad():
            output = model(dummy_input)
        
        print(f"âœ… å¯èƒ½çš„è¾“å…¥å°ºå¯¸ï¼š{dummy_input.shape}ï¼Œè¾“å‡ºå°ºå¯¸ï¼š{output.shape}")
        input_dim = dim
        break  # æ‰¾åˆ°å°±åœï¼Œä¸ç”¨ç»§ç»­äº†
    except Exception as e:
        continue

if input_dim is None:
    raise RuntimeError("âŒ æ²¡èƒ½æ‰¾åˆ°åˆé€‚çš„è¾“å…¥å°ºå¯¸ï¼Œè¯·æ‰©å¤§æœç´¢èŒƒå›´ã€‚")

# ==== å¯¼å‡ºåˆ° ONNX ====
print(f"ğŸš€ å¼€å§‹å¯¼å‡º ONNXï¼Œä½¿ç”¨è¾“å…¥å°ºå¯¸ï¼š{input_dim}")

dummy_input = torch.randn(1, input_dim)

torch.onnx.export(
    model,
    dummy_input,
    onnx_path,
    opset_version=opset,
    input_names=["input"],
    output_names=["output"],
    dynamic_axes={"input": {0: "batch_size"}, "output": {0: "batch_size"}}
)

print(f"ğŸ¯ å¯¼å‡ºæˆåŠŸï¼ONNXæ–‡ä»¶ä¿å­˜åœ¨ï¼š{onnx_path}")


```